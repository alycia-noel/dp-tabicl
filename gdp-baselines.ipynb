{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca71df09-3de4-4ccf-a4d8-590f278a2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diffprivlib import models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB as skl_gnb\n",
    "from diffprivlib.models import LogisticRegression, GaussianNB, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, f1_score\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba1c0d8-ad46-4392-a428-1fa07aea304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, eps, min, max, n):\n",
    "\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    categorical_columns_selector = selector(dtype_include=object)\n",
    "    # import pandas data train, test\n",
    "    train_filename = f'/home/ancarey/kennedy/karuna_data/original/{dataset}/{dataset}_original.csv'\n",
    "    test_filename = f'/home/ancarey/kennedy/karuna_data/original/{dataset}/{dataset}_original_test.csv'\n",
    "\n",
    "    df = pd.read_csv(train_filename)\n",
    "    df = df.dropna(axis=0)\n",
    "    if dataset == 'adult':\n",
    "        df = df.loc[df['native_country'] != 'Holand-Netherlands']\n",
    "    if dataset == 'car':\n",
    "        df['label'] = df['label'].map({0: 0, 1:1, 2:1, 3:1})\n",
    "    if dataset == 'diabetes' or dataset == 'heart':\n",
    "        df['label'] = df['label'].astype('bool')\n",
    "\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # sample dfTrain according to Pois(n / N)\n",
    "    items_to_sample = [(np.random.poisson(n / len(df)) >= 1) for i in range(len(df))]\n",
    "    df_sampled = df[items_to_sample]\n",
    "    \n",
    "    df_test = pd.read_csv(test_filename)\n",
    "    df_test = df_test.dropna(axis=0)\n",
    "    if dataset == 'car':\n",
    "        df_test['label'] = df_test['label'].map({0: 0, 1:1, 2:1, 3:1})\n",
    "    if dataset == 'diabetes' or dataset == 'heart':\n",
    "        df_test['label'] = df_test['label'].astype('bool')\n",
    "\n",
    "    large = ['adult', 'bank', 'calhousing', 'jungle']\n",
    "    df_test = pd.get_dummies(df_test)\n",
    "    if dataset in large:\n",
    "        df_test_sample = df_test.sample(n=int(len(df_test)*.1))\n",
    "    else: \n",
    "        df_test_sample = df_test.sample(n=int(len(df_test)*.75))\n",
    "        \n",
    "    y_train = df_sampled['label']\n",
    "    X_train = df_sampled.drop(columns=['label'])\n",
    "    y_test = df_test_sample['label']\n",
    "    X_test = df_test_sample.drop(columns=['label'])\n",
    "    # LR    \n",
    "    LR = LogisticRegression(epsilon=eps) #, bounds=(-1e5, 1e5)\n",
    "    LR.fit(X_train, y_train)\n",
    "    predictions = LR.predict(X_test)\n",
    "    acc_lr = accuracy_score(y_test, predictions)\n",
    "    f1_lr = f1_score(y_test, predictions)\n",
    "\n",
    "    # GaussianBayes\n",
    "    GB = skl_gnb() #, bounds=(-1e5, 1e5)\n",
    "    GB.fit(X_train, y_train)\n",
    "    predictions = GB.predict(X_test)\n",
    "    acc_gb = accuracy_score(y_test, predictions)\n",
    "    f1_gb = f1_score(y_test, predictions)\n",
    "\n",
    "    # RF\n",
    "    RF = RandomForestClassifier(epsilon=eps) #, bounds=(-1e5, 1e5)\n",
    "    RF.fit(X_train, y_train)\n",
    "    predictions = RF.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, predictions)\n",
    "    f1_rf = f1_score(y_test, predictions)\n",
    "\n",
    "    return acc_lr, f1_lr, acc_gb, f1_gb, acc_rf, f1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09dc8d2-9e60-46d6-975c-709b7b34c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(name):\n",
    "    if name == 'adult':\n",
    "        min = [0 for _ in range(102)]\n",
    "        max = [100, 50000, 5000, 40]\n",
    "        ones = [1 for _ in range(98)]\n",
    "        max.extend(ones)\n",
    "    elif name == 'bank':\n",
    "        min = -5000\n",
    "        max = 5e5\n",
    "    elif name == 'blood':\n",
    "        min = 0\n",
    "        max = 3e5\n",
    "    elif name == 'calhousing':\n",
    "        min = -124\n",
    "        max = 6e5\n",
    "    elif name == 'car':\n",
    "        min = 0\n",
    "        max = 4\n",
    "    elif name == 'diabetes':\n",
    "        min = 0\n",
    "        max = 600\n",
    "    elif name == 'heart':\n",
    "        min = -4\n",
    "        max = 500\n",
    "    elif name == 'jungle':\n",
    "        min = 0\n",
    "        max = 8\n",
    "\n",
    "    return min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917f9de1-8d99-4e8e-9789-2006c8067144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: jungle Epsilon: inf\n",
      "LR\n",
      "Acc: 0.73 0.015 F1: 0.74 0.02\n",
      "GB\n",
      "Acc: 0.744 0.021 F1: 0.749 0.027\n",
      "RF\n",
      "Acc: 0.688 0.044 F1: 0.671 0.067\n",
      "Dataset: jungle Epsilon: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m lr_f1s, gb_f1s, rf_f1s \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rs):\n\u001b[0;32m---> 11\u001b[0m     acc_lr, f1_lr, acc_gb, f1_gb, acc_rf, f1_rf \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     lr_accs\u001b[38;5;241m.\u001b[39mappend(acc_lr)\n\u001b[1;32m     13\u001b[0m     lr_f1s\u001b[38;5;241m.\u001b[39mappend(f1_lr)\n",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset, eps, min, max, n)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# RF\u001b[39;00m\n\u001b[1;32m     57\u001b[0m RF \u001b[38;5;241m=\u001b[39m RandomForestClassifier(epsilon\u001b[38;5;241m=\u001b[39meps) \u001b[38;5;66;03m#, bounds=(-1e5, 1e5)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mRF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m predictions \u001b[38;5;241m=\u001b[39m RF\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     60\u001b[0m acc_rf \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, predictions)\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/diffprivlib/models/forest.py:263\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Todo: Remove when scikit-learn v1.1 is a min requirement\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtree_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     trees \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    278\u001b[0m         delayed(_parallel_build_trees)(\n\u001b[1;32m    279\u001b[0m             tree\u001b[38;5;241m=\u001b[39mt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    289\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:200\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/diffprivlib/models/forest.py:455\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/diffprivlib/models/forest.py:442\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    439\u001b[0m fitting_tree \u001b[38;5;241m=\u001b[39m _FittingTree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[1;32m    440\u001b[0m                             random_state)\n\u001b[1;32m    441\u001b[0m fitting_tree\u001b[38;5;241m.\u001b[39mbuild()\n\u001b[0;32m--> 442\u001b[0m \u001b[43mfitting_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Load params from _FittingTree into sklearn.Tree\u001b[39;00m\n\u001b[1;32m    445\u001b[0m d \u001b[38;5;241m=\u001b[39m fitting_tree\u001b[38;5;241m.\u001b[39m__getstate__()\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/diffprivlib/models/forest.py:579\u001b[0m, in \u001b[0;36m_FittingTree.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting Tree must be built before calling fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 579\u001b[0m leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m unique_leaves \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(leaves)\n\u001b[1;32m    581\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_count, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses)))\n",
      "File \u001b[0;32m~/.conda/envs/pt/lib/python3.9/site-packages/diffprivlib/models/forest.py:614\u001b[0m, in \u001b[0;36m_FittingTree.apply\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    611\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m node\u001b[38;5;241m.\u001b[39mleft_child \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TREE_LEAF:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m:\n\u001b[1;32m    615\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[node\u001b[38;5;241m.\u001b[39mleft_child]\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eps = [float('inf'), 1, 2, 5, 10, 25, 50]\n",
    "datasets = ['jungle']\n",
    "rs = [3016, 3617, 300, 3300, 691, 307, 367, 3586]\n",
    "for d in datasets:\n",
    "    for e in eps:\n",
    "        print('Dataset:', d, 'Epsilon:', e)\n",
    "        min, max = get_bounds(d)\n",
    "        lr_accs, gb_accs, rf_accs = [], [], []\n",
    "        lr_f1s, gb_f1s, rf_f1s = [], [], []\n",
    "        for i, r in enumerate(rs):\n",
    "            acc_lr, f1_lr, acc_gb, f1_gb, acc_rf, f1_rf = main(d, e, min, max, r)\n",
    "            lr_accs.append(acc_lr)\n",
    "            lr_f1s.append(f1_lr)\n",
    "            gb_accs.append(acc_gb)\n",
    "            gb_f1s.append(f1_gb)\n",
    "            rf_accs.append(acc_rf)\n",
    "            rf_f1s.append(f1_rf)\n",
    "\n",
    "        print('LR')\n",
    "        print('Acc:', round(np.mean(np.array(lr_accs)),3), round(np.std(np.array(lr_accs)),3), 'F1:', round(np.mean(np.array(lr_f1s)),3), round(np.std(np.array(lr_f1s)),3))\n",
    "        print('GB')\n",
    "        print('Acc:', round(np.mean(np.array(gb_accs)),3), round(np.std(np.array(gb_accs)),3), 'F1:', round(np.mean(np.array(gb_f1s)),3), round(np.std(np.array(gb_f1s)),3))\n",
    "        print('RF')\n",
    "        print('Acc:', round(np.mean(np.array(rf_accs)),3), round(np.std(np.array(rf_accs)),3), 'F1:', round(np.mean(np.array(rf_f1s)),3), round(np.std(np.array(rf_f1s)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b58e9-8697-4576-81ad-9b535e7db04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d6b38-34d3-4a5c-b330-ebc13a8bf504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
